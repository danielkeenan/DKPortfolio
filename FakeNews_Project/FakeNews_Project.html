---
layout: default
---

<body>
    <h1>Fake and Real News Data Analysis Project</h1>
    <h2>Exploring Fake and Real News Datasets</h2>
    <p>In this project, I have performed some exploratory analysis into fake and real
        news datasets and performed feature selection and logistic regression to
         determine how well the model can perform.</p>
    <h3><a href="/DKPortfolio">Home</a></h3>
    <p><b><i><a href='https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset'>Data Source</a></b></i></p>
    <p><a href="/DKPortfolio/FakeNews_Project/FakeNews_Project_Vis.html">Just Visualisations</a></p>
    <p><a href="/DKPortfolio/FakeNews_Project/FakeNews_Project_Code.html">Just Code</a></p>    
    <p></p>
    <h3>Import statements:</h3>
    <pre><code>
        import numpy as np
        import pandas as pd
        from sklearn.feature_extraction.text import CountVectorizer
        from nltk.tokenize import RegexpTokenizer
        import plotly.graph_objects as go
        from sklearn.model_selection import train_test_split
        from sklearn.linear_model import LogisticRegression
        from sklearn.metrics import accuracy_score, f1_score, log_loss
        import seaborn as sns
        import matplotlib.pyplot as plt
        from sklearn.metrics import plot_confusion_matrix
        from sklearn.metrics import classification_report
        from wordcloud import WordCloud
    </code></pre>

    <h3>Reading in the datasets:</h3>
    <pre><code>
        fake_df = pd.read_csv('Fake.csv')
        fake_df.dropna(inplace=True)
        fake_df.head()
    </code></pre>
    <pre><code>
        real_df = pd.read_csv('True.csv')
        real_df.dropna(inplace=True)
        real_df.head()
    </code></pre>
    <img src = 'images/readcsv_fake.png'>
    <img src = 'images/readcsv_real.png'>

    <h3>Concatenating the two datasets:</h3>
    <pre><code>
        fake_df['class'] = np.zeros(fake_df.shape[0])
        real_df['class'] = np.ones(real_df.shape[0])
        
        news = pd.concat([fake_df, real_df])
    </code></pre>
    <img src = 'images/concat.png'>

    <h3>Combine the title and text columns:</h3>
    <pre><code>
        news['title_text'] = news['title'] + ' ' +news['text']
        news.drop(['title', 'text'], axis=1, inplace=True)
    </code></pre>
    <img src = 'images/combined_columns.png'>

    <h3>Visualising the difference in fake and real news:</h3>
    <pre><code>
        fig = go.Figure(data = [
        go.Pie(labels=['Fake','True'], values = list(news['class'].value_counts()),
               hole=0.3)
        ])
        
        fig.update_layout(title='Fake and Real News Ratio')
        fig.show()
    </code></pre>
    <img src = 'images/pie.png'>

    <h3>CountVectorizer:</h3>
    <pre><code>
        token = RegexpTokenizer(r'[a-zA-Z]+')

        cv = CountVectorizer(lowercase=True, 
                             stop_words='english',
                             ngram_range = (1,2), 
                             tokenizer = token.tokenize, 
                             max_features=5000)
        
        text_counts = cv.fit_transform(news['title_text'])
        text_counts
    </code></pre>

    <h3>Train Test Split:</h3>
    <pre><code>
        X = text_counts
        y = news['class']
        
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    </code></pre>

    <h3>Fitting the Logistic Regression Model:</h3>
    <pre><code>
        model = LogisticRegression(class_weight='balanced', penalty='l2', solver='liblinear', max_iter=1000)
        model.fit(X_train, y_train)
    </code></pre>
    
    <h3>Predicting the model on the training and testing sets:</h3>
    <pre><code>
        y_pred = model.predict(X_train)

        acc = accuracy_score(y_train, y_pred)
        f1 = f1_score(y_train, y_pred)
        l1 = log_loss(y_train, y_pred)
        
        print(f'(train) accuracy_score: {acc})')
        print(f'(train) f1_score: {f1})')
        print(f'(train) log_loss: {l1})')
    </code></pre>
    <pre><code>
        y_pred = model.predict(X_test)

        acc = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        l1 = log_loss(y_test, y_pred)
        
        print(f'(train) accuracy_score: {acc})')
        print(f'(train) f1_score: {f1})')
        print(f'(train) log_loss: {l1})')
    </code></pre>
    <img src = 'images/predict_train.png'>
    <img src = 'images/predict_test.png'>

    <h3>Confusion Matrix:</h3>
    <pre><code>
        disp = plot_confusion_matrix(model, X, y, display_labels=['Fake','True'], normalize=None)
        plt.grid(False)
        plt.show()
    </code></pre>
    <img src = 'images/confusion_matrix.png'>

    <h3>Classification Report:</h3>
    <pre><code>
        y_pred = model.predict(X)
        print(classification_report(y, y_pred, target_names=['Fake','True'], zero_division=0))
    </code></pre>
    <img src = 'images/classification_report.png'>

    <h3>Generating a WordCloud:</h3>
    <pre><code>
        top_features = {}
        for col, coef in zip(cv.get_feature_names(), model.coef_[0]):
            if np.abs(coef) > 0.3:
                top_features[col] = int(np.abs(coef)*100)
    </code></pre>
    <pre><code>
        x, y = np.ogrid[:300, :300]

        mask = (x - 150) ** 2 + (y - 150) ** 2 > 130 ** 2
        mask = 255 * mask.astype(int)
        
        wc = WordCloud(background_color='white', repeat=True, mask=mask, scale=2)
        wc.generate_from_frequencies(top_features)
        
        plt.figure(figsize=(15,15))
        plt.axis('off')
        plt.imshow(wc, interpolation='bilinear')
        plt.show()
    </code></pre>
    <img src = 'images/wordcloud.png'>
</body>